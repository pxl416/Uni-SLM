# models/Head/recognition.py
import torch
import torch.nn as nn
import torch.nn.functional as F


class RecognitionHeadCTC(nn.Module):
    def __init__(self,
                 in_dim: int,
                 num_classes: int,
                 hidden: int = 512,
                 nlayer: int = 2,
                 dropout: float = 0.1,
                 blank_id: int = None):
        """
        Continuous Sign Language Recognition (CSLR) Head with CTC Loss.
        ã€ä»…ç”¨äºè¯„ä¼°ï¼Œä¸å‚ä¸è®­ç»ƒã€‘

        Args:
            in_dim: è¾“å…¥ç‰¹å¾ç»´åº¦ (æ¥è‡ª Encoderï¼Œä¾‹å¦‚ PoseEncoder/RGBEncoder èåˆå)
            num_classes: è¯è¡¨å¤§å° (å« blank)
            hidden: Transformer ç¼–ç ç»´åº¦
            nlayer: Transformer å±‚æ•°
            dropout: dropout æ¦‚ç‡
            blank_id: blank çš„ç´¢å¼•ï¼Œé»˜è®¤æ˜¯ num_classes-1
        """
        super().__init__()
        self.num_classes = num_classes
        self.blank_id = blank_id if blank_id is not None else num_classes - 1

        # æ˜ å°„åˆ° hidden ç»´åº¦
        self.proj = nn.Linear(in_dim, hidden)

        # Transformer encoder
        enc_layer = nn.TransformerEncoderLayer(
            d_model=hidden,
            nhead=8,
            dim_feedforward=hidden * 4,
            dropout=dropout,
            batch_first=True
        )
        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=nlayer)

        # åˆ†ç±»å™¨
        self.classifier = nn.Linear(hidden, num_classes)

        # ğŸš« å†»ç»“æ‰€æœ‰å‚æ•°ï¼Œä¸å‚ä¸è®­ç»ƒ
        self._freeze_parameters()

    def _freeze_parameters(self):
        """å†»ç»“æ‰€æœ‰å‚æ•°ï¼Œç¡®ä¿ä¸å‚ä¸æ¢¯åº¦æ›´æ–°"""
        for param in self.parameters():
            param.requires_grad = False
        self.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼

    def forward(self, seq: torch.Tensor, src_key_padding_mask=None) -> torch.Tensor:
        """
        Args:
            seq: [B, T, D]  è¾“å…¥åºåˆ—ç‰¹å¾
            src_key_padding_mask: [B, T]  padding mask (True=paddingä½ç½®)
        Returns:
            logits: [B, T, V]  åˆ†ç±» logits
        """
        # ä½¿ç”¨ torch.no_grad() ç¡®ä¿ä¸è®¡ç®—æ¢¯åº¦
        with torch.no_grad():
            x = self.proj(seq)  # [B, T, H]
            x = self.encoder(x, src_key_padding_mask=src_key_padding_mask)
            logits = self.classifier(x)  # [B, T, V]
        return logits

    def compute_loss(self, logits, targets, input_lengths, target_lengths) -> torch.Tensor:
        """
        Compute CTC loss for evaluation only.

        Args:
            logits: [B, T, V]
            targets: LongTensor, shape [sum(target_lengths)] ç¨€ç–æ‹¼æ¥çš„æ ‡ç­¾
            input_lengths: LongTensor, shape [B] æ¯ä¸ªæ ·æœ¬çš„è¾“å…¥é•¿åº¦
            target_lengths: LongTensor, shape [B] æ¯ä¸ªæ ·æœ¬çš„æ ‡ç­¾é•¿åº¦
        """
        assert logits.size(1) >= int(input_lengths.max()), \
            f"Input length {int(input_lengths.max())} exceeds logit length {logits.size(1)}"

        with torch.no_grad():
            log_probs = F.log_softmax(logits, dim=-1).transpose(0, 1)  # [T, B, V]
            return F.ctc_loss(
                log_probs,
                targets,
                input_lengths,
                target_lengths,
                blank=self.blank_id,
                zero_infinity=True
            )

    def compute_metrics(self, features, targets, input_lengths, target_lengths):
        """
        è®¡ç®—è¯†åˆ«ä»»åŠ¡çš„è¯„ä¼°æŒ‡æ ‡
        Returns:
            dict: åŒ…å«å„ç§è¯„ä¼°æŒ‡æ ‡çš„å­—å…¸
        """
        with torch.no_grad():
            # å‰å‘ä¼ æ’­è·å–logits
            logits = self.forward(features)

            # è®¡ç®—CTCæŸå¤±
            ctc_loss = self.compute_loss(logits, targets, input_lengths, target_lengths)

            # å¯ä»¥æ·»åŠ æ›´å¤šè¯„ä¼°æŒ‡æ ‡
            metrics = {
                "ctc_loss": ctc_loss.item(),
                "perplexity": torch.exp(ctc_loss).item(),
            }

            # è¿™é‡Œå¯ä»¥æ·»åŠ è¯†åˆ«å‡†ç¡®ç‡ã€ç¼–è¾‘è·ç¦»ç­‰æŒ‡æ ‡
            # metrics.update(self._compute_accuracy(logits, targets, input_lengths))

            return metrics

    def train(self, mode: bool = True):
        """
        é‡å†™trainæ–¹æ³•ï¼Œç¡®ä¿å§‹ç»ˆå¤„äºè¯„ä¼°æ¨¡å¼
        é˜²æ­¢æ„å¤–è¢«è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼
        """
        return super().train(False)  # å¼ºåˆ¶ä¿æŒè¯„ä¼°æ¨¡å¼

    def __repr__(self):
        return f"RecognitionHeadCTC(in_dim={self.proj.in_features}, " \
               f"num_classes={self.num_classes}, " \
               f"hidden={self.proj.out_features}, " \
               f"nlayer={len(self.encoder.layers)}, " \
               f"frozen=True)"